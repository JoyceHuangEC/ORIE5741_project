{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the data. We will also print a list of each columns together with its datatype, using the \"type\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(26)\n",
    "df = pd.read_csv('tmdb_5000_movies.csv') # Load in the csv file \n",
    "\n",
    "feature_names = df.columns\n",
    "for i in range(len(feature_names)):\n",
    "    print(str(i), \"\\t\", str(feature_names[i]),\"\\t\\t\\t\", str(type(df.iloc[0,i])))\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dealing with Nan/empty data\n",
    "\n",
    "Our goal is to predict the success of a movie (represented by its revenue) provided a list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete id column (which is not relevent to our task)\n",
    "df = df.drop([\"id\"], axis=1)\n",
    "print(df.shape)\n",
    "\n",
    "feature_names = df.columns\n",
    "\n",
    "# delete rows which contains empty field\n",
    "for feature in feature_names:\n",
    "    if (feature != \"homepage\" and feature != \"tagline\"):\n",
    "        df[feature].replace('', np.nan, inplace=True)\n",
    "        df = df[~df[feature].isna()]\n",
    "    else:\n",
    "        df[feature].replace(np.nan, \"\", inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Train/Test\n",
    "\n",
    "optional: k-fold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac = 1) # we shuffle the data so that our train/test split will be truly random\n",
    "\n",
    "train_proportion = 0.8\n",
    "n = len(df)\n",
    "print('Size of dataset: ', str(n))\n",
    "\n",
    "# Put the first ntrain observations in the DataFrame df into the training set, and the rest into the test set\n",
    "t = int(train_proportion * n)\n",
    "\n",
    "target = df['revenue']\n",
    "data = df.loc[:, ~df.columns.isin(['revenue'])]\n",
    "\n",
    "# the following variable records the features of examples in the training set\n",
    "train_x = data.iloc[0:t]\n",
    "# the following variable records the features of examples in the test set\n",
    "test_x = data.iloc[t:]\n",
    "# the following variable records the labels of examples in the training set\n",
    "train_y = target[0:t]\n",
    "# the following variable records the labels of examples in the test set\n",
    "test_y = target[t:]\n",
    "\n",
    "# let's take a look\n",
    "print('Training dataset: ', train_x)\n",
    "print('Training y: ',train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Boolean/Int Data\n",
    "\n",
    "homepage: whether a movie has a home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change homepage to boolean feature: whether a movie has a home page\n",
    "def string_to_bool(string):\n",
    "    if (string != \"\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# change tagline to int feature: length of the tagline (if no tagline, len = 0)\n",
    "def string_to_int(string):\n",
    "    try:\n",
    "        return len(string.split())\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "label_str_to_bool = [\"homepage\"]\n",
    "df_homepage = df.loc[:, df.columns.isin(label_str_to_bool)].applymap(string_to_bool)\n",
    "label_str_to_int = [\"tagline\"]\n",
    "df_tagline = df.loc[:, df.columns.isin(label_str_to_int)].applymap(string_to_int)\n",
    "\n",
    "print(df_tagline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vals_homepage = train_x.loc[:, train_x.columns.isin(label_str_to_bool)].applymap(string_to_bool)\n",
    "train_vals_homepage = np.asarray(train_vals_homepage)\n",
    "test_vals_homepage = test_x.loc[:, test_x.columns.isin(label_str_to_bool)].applymap(string_to_bool)\n",
    "test_vals_homepage = np.asarray(test_vals_homepage)\n",
    "\n",
    "train_vals_tagline = train_x.loc[:, train_x.columns.isin(label_str_to_int)].applymap(string_to_int)\n",
    "train_vals_tagline = np.asarray(train_vals_tagline)\n",
    "test_vals_tagline = test_x.loc[:, test_x.columns.isin(label_str_to_int)].applymap(string_to_int)\n",
    "test_vals_tagline = np.asarray(test_vals_tagline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Manyhot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string):\n",
    "    data = json.loads(string)\n",
    "    result = {d['id']: d['name'] for d in data}\n",
    "    return result.values()\n",
    "\n",
    "def manyhot(column=None, col=None):\n",
    "    cat_to_idx = {cat: i for i, cat in enumerate(col)}\n",
    "    manyhot_vectors = []\n",
    "    for entry in column:\n",
    "        vec = [0] * len(col)\n",
    "        for ele in entry:\n",
    "            if (ele in cat_to_idx):\n",
    "                vec[cat_to_idx[ele]] = 1\n",
    "        manyhot_vectors.append(vec)\n",
    "    return np.asarray(manyhot_vectors)\n",
    "\n",
    "label_str_to_dict = ['genres', 'keywords']\n",
    "train_vals_genres_keywords = train_x.loc[:, train_x.columns.isin(label_str_to_dict)].applymap(string_to_list)\n",
    "test_vals_genres_keywords = test_x.loc[:, test_x.columns.isin(label_str_to_dict)].applymap(string_to_list)\n",
    "\n",
    "# set of all genres\n",
    "all_genres = functools.reduce(lambda x, y: x.union(y), train_vals_genres_keywords['genres'], set())\n",
    "train_vals_genres = manyhot(column=train_vals_genres_keywords['genres'], col=all_genres)\n",
    "test_vals_genres = manyhot(column=test_vals_genres_keywords['genres'], col=all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists into a single list using a list comprehension\n",
    "flat_keywords_list = [keyword for sublist in train_vals_genres_keywords['keywords'] for keyword in sublist]\n",
    "keywords_freq = Counter(flat_keywords_list)\n",
    "# Create a list of keys to remove\n",
    "keys_to_remove = [key for key, count in keywords_freq.items() if count <= 3]\n",
    "# Remove the keys from the dictionary\n",
    "for key in keys_to_remove:\n",
    "    del keywords_freq[key]\n",
    "all_keywords = keywords_freq.keys()\n",
    "train_vals_keywords = manyhot(column=train_vals_genres_keywords['keywords'], col=all_keywords)\n",
    "test_vals_keywords = manyhot(column=test_vals_genres_keywords['keywords'], col=all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offset = np.ones((train_vals_homepage.shape[0], 1))\n",
    "test_offset = np.ones((test_vals_homepage.shape[0], 1))\n",
    "train_vals = np.concatenate((train_vals_homepage, train_vals_tagline, train_vals_genres, train_vals_keywords, train_offset), axis=1)\n",
    "test_vals = np.concatenate((test_vals_homepage, test_vals_tagline, test_vals_genres, test_vals_keywords, test_offset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just computes the mean squared error\n",
    "def MSE(y, pred):\n",
    "    # YOUR CODE HERE\n",
    "    return np.mean(np.square(y - pred))\n",
    "\n",
    "# This function plots the main diagonal;for a \"predicted vs true\" plot with perfect predictions, all data lies on this line\n",
    "def plotDiagonal(xmin, xmax):\n",
    "    xsamples = np.arange(xmin,xmax,step=0.01)\n",
    "    plt.plot(xsamples,xsamples,c='black')\n",
    "\n",
    "# This helper function plots x vs y and labels the axes\n",
    "def plotdata(x=None,y=None,xname=None,yname=None,margin=0.05,plotDiag=True,zeromin=False):\n",
    "    plt.scatter(x,y,label='data')\n",
    "    plt.xlabel(xname)\n",
    "    plt.ylabel(yname)\n",
    "    range_x = max(x) - min(x)\n",
    "    range_y = max(y) - min(y)\n",
    "    if plotDiag:\n",
    "        plotDiagonal(min(x)-margin*range_x,max(x)+margin*range_x)\n",
    "    if zeromin:\n",
    "        plt.xlim(0.0,max(x)+margin*range_x)\n",
    "        plt.ylim(0.0,max(y)+margin*range_y)\n",
    "    else:\n",
    "        plt.xlim(min(x)-margin*range_x,max(x)+margin*range_x)\n",
    "        plt.ylim(min(y)-margin*range_y,max(y)+margin*range_y)\n",
    "    plt.show()\n",
    "\n",
    "# This function plots the predicted labels vs the actual labels (We only plot the first 1000 points to avoid slow plots)\n",
    "def plot_pred_true(test_pred=None, test_y=None, max_points = 1000):\n",
    "    plotdata(test_pred[1:max_points], test_y[1:max_points],'Predicted', 'True', zeromin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs OLS and bypasses any SVD (Singular Value Decomposition) convergence errors by refitting the model\n",
    "def run_OLS(train_y, test_y, train_vals, test_vals):\n",
    "    ols_model = sm.regression.linear_model.OLS(train_y, train_vals)\n",
    "    while True: # Bypasses SVD convergence assertion error\n",
    "        try:\n",
    "            results = ols_model.fit()\n",
    "            break\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    w = np.array(results.params).reshape([len(results.params),1])\n",
    "\n",
    "    train_pred = np.matmul(train_vals,w)\n",
    "    test_pred = np.matmul(test_vals,w)\n",
    "\n",
    "    train_MSE = MSE(train_y, train_pred.flatten())\n",
    "    test_MSE = MSE(test_y, test_pred.flatten())\n",
    "    \n",
    "    return train_MSE, test_MSE, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))\n",
    "\n",
    "plot_pred_true(test_pred.flatten(), test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1788)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a nonlinear model\n",
    "model = MLPClassifier(hidden_layer_sizes=(100, 50))\n",
    "\n",
    "# Train the model on the train set\n",
    "model.fit(train_vals, train_y)\n",
    "\n",
    "# Predict the labels of the test set\n",
    "y_pred = model.predict(test_vals)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "accuracy = accuracy_score(test_y, y_pred)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv5741': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "557b5432e63c25bc0a47064c92a1c7acaa548717fa75dcf313c4d9862074aa00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
