{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import functools\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we load the data. We will also print a list of each columns together with its datatype, using the \"type\" function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t budget \t\t\t <class 'numpy.int64'>\n",
      "1 \t genres \t\t\t <class 'str'>\n",
      "2 \t homepage \t\t\t <class 'str'>\n",
      "3 \t id \t\t\t <class 'numpy.int64'>\n",
      "4 \t keywords \t\t\t <class 'str'>\n",
      "5 \t original_language \t\t\t <class 'str'>\n",
      "6 \t original_title \t\t\t <class 'str'>\n",
      "7 \t overview \t\t\t <class 'str'>\n",
      "8 \t popularity \t\t\t <class 'numpy.float64'>\n",
      "9 \t production_companies \t\t\t <class 'str'>\n",
      "10 \t production_countries \t\t\t <class 'str'>\n",
      "11 \t release_date \t\t\t <class 'str'>\n",
      "12 \t revenue \t\t\t <class 'numpy.int64'>\n",
      "13 \t runtime \t\t\t <class 'numpy.float64'>\n",
      "14 \t spoken_languages \t\t\t <class 'str'>\n",
      "15 \t status \t\t\t <class 'str'>\n",
      "16 \t tagline \t\t\t <class 'str'>\n",
      "17 \t title \t\t\t <class 'str'>\n",
      "18 \t vote_average \t\t\t <class 'numpy.float64'>\n",
      "19 \t vote_count \t\t\t <class 'numpy.int64'>\n",
      "(4803, 20)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "df = pd.read_csv('tmdb_5000_movies.csv') # Load in the csv file \n",
    "\n",
    "feature_names = df.columns\n",
    "for i in range(len(feature_names)):\n",
    "    print(str(i), \"\\t\", str(feature_names[i]),\"\\t\\t\\t\", str(type(df.iloc[0,i])))\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dealing with Nan/empty data\n",
    "\n",
    "Our goal is to predict the success of a movie (represented by its revenue) provided a list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4803, 19)\n",
      "(4799, 19)\n"
     ]
    }
   ],
   "source": [
    "# delete id column (which is not relevent to our task)\n",
    "df = df.drop([\"id\"], axis=1)\n",
    "print(df.shape)\n",
    "\n",
    "feature_names = df.columns\n",
    "\n",
    "# delete rows which contains empty field\n",
    "for feature in feature_names:\n",
    "    if (feature != \"homepage\" and feature != \"tagline\"):\n",
    "        df[feature].replace('', np.nan, inplace=True)\n",
    "        df = df[~df[feature].isna()]\n",
    "    else:\n",
    "        df[feature].replace(np.nan, \"\", inplace=True)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split Train/Test\n",
    "\n",
    "optional: k-fold etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of dataset:  4799\n",
      "Training dataset:          budget                                             genres  \\\n",
      "3345         0  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
      "3836         0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 35, \"nam...   \n",
      "2810  11000000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
      "1276  40000000  [{\"id\": 18, \"name\": \"Drama\"}, {\"id\": 35, \"name...   \n",
      "326   95000000  [{\"id\": 10749, \"name\": \"Romance\"}, {\"id\": 14, ...   \n",
      "...        ...                                                ...   \n",
      "1746  35000000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"nam...   \n",
      "4742     65000  [{\"id\": 99, \"name\": \"Documentary\"}, {\"id\": 35,...   \n",
      "2324  16500000  [{\"id\": 878, \"name\": \"Science Fiction\"}, {\"id\"...   \n",
      "2759  13000000  [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 10749, \"...   \n",
      "956   45000000  [{\"id\": 27, \"name\": \"Horror\"}, {\"id\": 28, \"nam...   \n",
      "\n",
      "                                  homepage  \\\n",
      "3345  http://www.definitelymaybemovie.com/   \n",
      "3836                                         \n",
      "2810                                         \n",
      "1276    http://www.thousandwordsmovie.com/   \n",
      "326    http://movies.disney.com/cinderella   \n",
      "...                                    ...   \n",
      "1746                                         \n",
      "4742                                         \n",
      "2324                                         \n",
      "2759                                         \n",
      "956                                          \n",
      "\n",
      "                                               keywords original_language  \\\n",
      "3345  [{\"id\": 725, \"name\": \"lovesickness\"}, {\"id\": 2...                en   \n",
      "3836                                                 []                en   \n",
      "2810  [{\"id\": 3687, \"name\": \"graduation\"}, {\"id\": 61...                en   \n",
      "1276  [{\"id\": 9468, \"name\": \"liar\"}, {\"id\": 11204, \"...                en   \n",
      "326   [{\"id\": 995, \"name\": \"cinderella\"}, {\"id\": 234...                en   \n",
      "...                                                 ...               ...   \n",
      "1746                [{\"id\": 3741, \"name\": \"talk show\"}]                en   \n",
      "4742  [{\"id\": 1706, \"name\": \"experiment\"}, {\"id\": 37...                en   \n",
      "2324  [{\"id\": 803, \"name\": \"android\"}, {\"id\": 1568, ...                en   \n",
      "2759  [{\"id\": 4513, \"name\": \"blind date\"}, {\"id\": 96...                en   \n",
      "956   [{\"id\": 779, \"name\": \"martial arts\"}, {\"id\": 1...                en   \n",
      "\n",
      "                                   original_title  \\\n",
      "3345                            Definitely, Maybe   \n",
      "3836                            I Got the Hook Up   \n",
      "2810                                 American Pie   \n",
      "1276                             A Thousand Words   \n",
      "326                                    Cinderella   \n",
      "...                                           ...   \n",
      "1746                  Welcome Home Roscoe Jenkins   \n",
      "4742                                Super Size Me   \n",
      "2324  Austin Powers: International Man of Mystery   \n",
      "2759                                          Woo   \n",
      "956                     Resident Evil: Apocalypse   \n",
      "\n",
      "                                               overview  popularity  \\\n",
      "3345  When Will decides to tell his daughter the sto...   29.173266   \n",
      "3836  Two broke buddies feel lucky when they come up...    0.593068   \n",
      "2810  At a high-school party, four friends find that...   60.767168   \n",
      "1276  Jack McCall is a fast-talking literary agent, ...   13.119133   \n",
      "326   When her father unexpectedly passes away, youn...  101.187052   \n",
      "...                                                 ...         ...   \n",
      "1746  Martin Lawrence leads an all-star cast, includ...    6.248273   \n",
      "4742  Morgan Spurlock subjects himself to a diet bas...   10.400603   \n",
      "2324  As a swingin' fashion photographer by day and ...   36.157160   \n",
      "2759  Gorgeous and extraverted Woo meets insecure an...    1.750054   \n",
      "956   As the city is locked down under quarantine, A...   29.880122   \n",
      "\n",
      "                                   production_companies  \\\n",
      "3345  [{\"name\": \"Universal Pictures\", \"id\": 33}, {\"n...   \n",
      "3836  [{\"name\": \"Dimension Films\", \"id\": 7405}, {\"na...   \n",
      "2810  [{\"name\": \"Universal Pictures\", \"id\": 33}, {\"n...   \n",
      "1276  [{\"name\": \"Paramount Pictures\", \"id\": 4}, {\"na...   \n",
      "326   [{\"name\": \"Walt Disney Pictures\", \"id\": 2}, {\"...   \n",
      "...                                                 ...   \n",
      "1746  [{\"name\": \"Universal Pictures\", \"id\": 33}, {\"n...   \n",
      "4742         [{\"name\": \"Kathbur Pictures\", \"id\": 8735}]   \n",
      "2324  [{\"name\": \"New Line Cinema\", \"id\": 12}, {\"name...   \n",
      "2759  [{\"name\": \"New Line Cinema\", \"id\": 12}, {\"name...   \n",
      "956   [{\"name\": \"Impact Pictures\", \"id\": 248}, {\"nam...   \n",
      "\n",
      "                                   production_countries release_date  runtime  \\\n",
      "3345  [{\"iso_3166_1\": \"FR\", \"name\": \"France\"}, {\"iso...   2008-02-08    112.0   \n",
      "3836  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1998-05-27     93.0   \n",
      "2810  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1999-07-09     95.0   \n",
      "1276  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2012-03-07     91.0   \n",
      "326   [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2015-03-12    105.0   \n",
      "...                                                 ...          ...      ...   \n",
      "1746  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2008-02-08    114.0   \n",
      "4742  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2004-01-17    100.0   \n",
      "2324  [{\"iso_3166_1\": \"DE\", \"name\": \"Germany\"}, {\"is...   1997-05-02     94.0   \n",
      "2759  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   1998-05-08     84.0   \n",
      "956   [{\"iso_3166_1\": \"GB\", \"name\": \"United Kingdom\"...   2004-09-10     94.0   \n",
      "\n",
      "                              spoken_languages    status  \\\n",
      "3345  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "3836  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "2810  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "1276  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "326   [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "...                                        ...       ...   \n",
      "1746  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "4742  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "2324  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "2759  [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "956   [{\"iso_639_1\": \"en\", \"name\": \"English\"}]  Released   \n",
      "\n",
      "                                                tagline  \\\n",
      "3345  Three relationships. Three disasters. One last...   \n",
      "3836  A truckload of cell phones... turns into a boa...   \n",
      "2810             There's nothing like your first piece.   \n",
      "1276  He only has 1000 words left to discover what m...   \n",
      "326                     Midnight is just the beginning.   \n",
      "...                                                 ...   \n",
      "1746  Roscoe Jenkins aims for the heartstrings and f...   \n",
      "4742  The first ever reality-based movie ... everyth...   \n",
      "2324  If he were any cooler, he'd still be frozen, b...   \n",
      "2759        It's Woo's world.. we're just living in it.   \n",
      "956                            You're all going to die.   \n",
      "\n",
      "                                            title  vote_average  vote_count  \n",
      "3345                            Definitely, Maybe           6.7         620  \n",
      "3836                            I Got the Hook Up           5.4           8  \n",
      "2810                                 American Pie           6.4        2296  \n",
      "1276                             A Thousand Words           6.0         373  \n",
      "326                                    Cinderella           6.7        2374  \n",
      "...                                           ...           ...         ...  \n",
      "1746                  Welcome Home Roscoe Jenkins           5.7          57  \n",
      "4742                                Super Size Me           6.6         506  \n",
      "2324  Austin Powers: International Man of Mystery           6.5        1013  \n",
      "2759                                          Woo           5.5          10  \n",
      "956                     Resident Evil: Apocalypse           6.1        1267  \n",
      "\n",
      "[3839 rows x 18 columns]\n",
      "Training y:  3345     55447968\n",
      "3836            0\n",
      "2810    235483004\n",
      "1276     22044277\n",
      "326     543514353\n",
      "          ...    \n",
      "1746     43650785\n",
      "4742     28575078\n",
      "2324     67683989\n",
      "2759      8026971\n",
      "956     129394835\n",
      "Name: revenue, Length: 3839, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(frac = 1) # we shuffle the data so that our train/test split will be truly random\n",
    "\n",
    "train_proportion = 0.8\n",
    "n = len(df)\n",
    "print('Size of dataset: ', str(n))\n",
    "\n",
    "# Put the first ntrain observations in the DataFrame df into the training set, and the rest into the test set\n",
    "t = int(train_proportion * n)\n",
    "\n",
    "target = df['revenue']\n",
    "data = df.loc[:, ~df.columns.isin(['revenue'])]\n",
    "\n",
    "# the following variable records the features of examples in the training set\n",
    "train_x = data.iloc[0:t]\n",
    "# the following variable records the features of examples in the test set\n",
    "test_x = data.iloc[t:]\n",
    "# the following variable records the labels of examples in the training set\n",
    "train_y = target[0:t]\n",
    "# the following variable records the labels of examples in the test set\n",
    "test_y = target[t:]\n",
    "\n",
    "# let's take a look\n",
    "print('Training dataset: ', train_x)\n",
    "print('Training y: ',train_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Boolean and Real Value Data\n",
    "\n",
    "homepage: whether a movie has a home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change homepage to boolean feature: whether a movie has a home page\n",
    "def string_to_bool(string):\n",
    "    if (string != \"\"):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# change tagline to int feature: length of the tagline (if no tagline, len = 0)\n",
    "def string_to_int(string):\n",
    "    try:\n",
    "        return len(string.split())\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_x['vote_count'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_str_to_bool = ['homepage']\n",
    "label_str_to_int = ['tagline']\n",
    "label_str_to_real = ['budget', 'popularity', 'runtime', 'vote_average', 'vote_count']\n",
    "\n",
    "train_vals_homepage = np.asarray(train_x.loc[:, train_x.columns.isin(label_str_to_bool)].applymap(string_to_bool))\n",
    "test_vals_homepage = np.asarray(test_x.loc[:, test_x.columns.isin(label_str_to_bool)].applymap(string_to_bool))\n",
    "\n",
    "train_vals_tagline = np.asarray(train_x.loc[:, train_x.columns.isin(label_str_to_int)].applymap(string_to_int))\n",
    "test_vals_tagline = np.asarray(test_x.loc[:, test_x.columns.isin(label_str_to_int)].applymap(string_to_int))\n",
    "\n",
    "train_vals_real = np.asarray(train_x.loc[:, train_x.columns.isin(label_str_to_real)])\n",
    "test_vals_real = np.asarray(test_x.loc[:, test_x.columns.isin(label_str_to_real)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Onehot Data\n",
    "\n",
    "features: production company，country, spoken language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'hi' 'ru' 'ro' 'da' 'te' 'ja' 'es' 'fa' 'sv' 'fr' 'ta' 'de' 'ko'\n",
      " 'xx' 'zh' 'pt' 'it' 'cn' 'id' 'th' 'he' 'tr' 'ar' 'no' 'af' 'nl' 'sl'\n",
      " 'ky' 'vi' 'el' 'cs' 'hu']\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def string_to_list(string):\n",
    "    data = json.loads(string)\n",
    "    result = {d['id']: d['name'] for d in data}\n",
    "    return result.values()\n",
    "\n",
    "label_str_onehot = [\n",
    "    'original_language', \n",
    "]\n",
    "\n",
    "# print(train_x.columns)\n",
    "\n",
    "#Sets of all categories in a particular column\n",
    "label_onehot_set = [train_x.loc[:, label].fillna('NaN').unique() for label in label_str_onehot]\n",
    "print(label_onehot_set[0])\n",
    "\n",
    "def onehot(column=None, col=None):\n",
    "    # print(col)\n",
    "    result = []\n",
    "    for data in column:\n",
    "        # print(data)\n",
    "        dic = dict.fromkeys(list(col), 0)\n",
    "        # print(dic)\n",
    "        if data in dic.keys():\n",
    "            dic[data] += 1\n",
    "        result.append(list(dic.values()))\n",
    "    return result\n",
    "\n",
    "train_vals_onehot = train_x.loc[:, train_x.columns.isin(label_str_onehot)]\n",
    "test_vals_onehot = test_x.loc[:, test_x.columns.isin(label_str_onehot)]\n",
    "\n",
    "def process_onehot():\n",
    "    trains = np.ones((len(train_vals_onehot),1))\n",
    "    tests = np.ones((len(test_vals_onehot),1))\n",
    "    for i in range(len(label_str_onehot)):\n",
    "        train_data_col = train_vals_onehot[label_str_onehot[-i]]\n",
    "        # print(label_str_onehot[-i])\n",
    "        test_data_col = test_vals_onehot[label_str_onehot[-i]]\n",
    "        feature_list = label_onehot_set[-i]\n",
    "        train_vector = onehot(train_data_col, feature_list)\n",
    "        # print(feature_list)\n",
    "        test_vector = onehot(test_data_col, feature_list)\n",
    "        trains = np.concatenate((train_vector, trains), 1)\n",
    "        tests = np.concatenate((test_vector, tests), 1)\n",
    "    # print(trains[:, :-1].shape)\n",
    "    # print(trains[:, :-1])\n",
    "    return trains[:, :-1], tests[:, :-1]\n",
    "\n",
    "train_vals_onehot, test_vals_onehot = process_onehot()\n",
    "print(train_vals_onehot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Manyhot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_list(string):\n",
    "    data = json.loads(string)\n",
    "    result = {d['id']: d['name'] for d in data}\n",
    "    return result.values()\n",
    "\n",
    "def string_to_list_prod_countries(string):\n",
    "    data = json.loads(string)\n",
    "    result = {d['iso_3166_1']: d['iso_3166_1'] for d in data}\n",
    "    return result.values()\n",
    "\n",
    "def string_to_list_spoken_lang(string):\n",
    "    data = json.loads(string)\n",
    "    result = {d['iso_639_1']: d['iso_639_1'] for d in data}\n",
    "    return result.values()\n",
    "\n",
    "def manyhot(column=None, col=None):\n",
    "    cat_to_idx = {cat: i for i, cat in enumerate(col)}\n",
    "    manyhot_vectors = []\n",
    "    for entry in column:\n",
    "        vec = [0] * len(col)\n",
    "        for ele in entry:\n",
    "            if (ele in cat_to_idx):\n",
    "                vec[cat_to_idx[ele]] = 1\n",
    "        manyhot_vectors.append(vec)\n",
    "    return np.asarray(manyhot_vectors)\n",
    "\n",
    "label_str_to_dict = ['genres', 'keywords', 'production_companies']\n",
    "train_vals_genres_keywords = train_x.loc[:, train_x.columns.isin(label_str_to_dict)].applymap(string_to_list)\n",
    "test_vals_genres_keywords = test_x.loc[:, test_x.columns.isin(label_str_to_dict)].applymap(string_to_list)\n",
    "\n",
    "# set of all genres\n",
    "all_genres = functools.reduce(lambda x, y: x.union(y), train_vals_genres_keywords['genres'], set())\n",
    "train_vals_genres = manyhot(column=train_vals_genres_keywords['genres'], col=all_genres)\n",
    "test_vals_genres = manyhot(column=test_vals_genres_keywords['genres'], col=all_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists into a single list using a list comprehension\n",
    "prod_company_list = [company for sublist in train_vals_genres_keywords['production_companies'] for company in sublist]\n",
    "prod_company_freq = Counter(prod_company_list)\n",
    "# Create a list of companies to remove\n",
    "prod_company_to_remove = [company for company, count in prod_company_freq.items() if count <= 3]\n",
    "# Remove the keys from the dictionary\n",
    "for company in prod_company_to_remove:\n",
    "    del prod_company_freq[company]\n",
    "all_prod_companies = prod_company_freq.keys()\n",
    "train_vals_prod_company = manyhot(column=train_vals_genres_keywords['production_companies'], col=all_prod_companies)\n",
    "test_vals_prod_company = manyhot(column=test_vals_genres_keywords['production_companies'], col=all_prod_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list of lists into a single list using a list comprehension\n",
    "flat_keywords_list = [keyword for sublist in train_vals_genres_keywords['keywords'] for keyword in sublist]\n",
    "keywords_freq = Counter(flat_keywords_list)\n",
    "# Create a list of keys to remove\n",
    "keys_to_remove = [key for key, count in keywords_freq.items() if count <= 3]\n",
    "# Remove the keys from the dictionary\n",
    "for key in keys_to_remove:\n",
    "    del keywords_freq[key]\n",
    "all_keywords = keywords_freq.keys()\n",
    "train_vals_keywords = manyhot(column=train_vals_genres_keywords['keywords'], col=all_keywords)\n",
    "test_vals_keywords = manyhot(column=test_vals_genres_keywords['keywords'], col=all_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature of spoken language\n",
    "train_spoken_lang_keywords = train_x.loc[:, train_x.columns.isin(['spoken_languages'])].applymap(string_to_list_spoken_lang)\n",
    "test_spoken_lang_keywords = test_x.loc[:, test_x.columns.isin(['spoken_languages'])].applymap(string_to_list_spoken_lang)\n",
    "# set of all spoken lang\n",
    "all_lang = functools.reduce(lambda x, y: x.union(y), train_spoken_lang_keywords['spoken_languages'], set())\n",
    "train_vals_lang = manyhot(column=train_spoken_lang_keywords['spoken_languages'], col=all_lang)\n",
    "test_vals_lang = manyhot(column=test_spoken_lang_keywords['spoken_languages'], col=all_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature of production_countries\n",
    "train_prod_country_keywords = train_x.loc[:, train_x.columns.isin(['production_countries'])].applymap(string_to_list_prod_countries)\n",
    "test_prod_country_keywords = test_x.loc[:, test_x.columns.isin(['production_countries'])].applymap(string_to_list_prod_countries)\n",
    "# set of all spoken lang\n",
    "all_prod_country = functools.reduce(lambda x, y: x.union(y), train_prod_country_keywords['production_countries'], set())\n",
    "train_vals_prod_country = manyhot(column=train_prod_country_keywords['production_countries'], col=all_prod_country)\n",
    "test_vals_prod_country = manyhot(column=test_prod_country_keywords['production_countries'], col=all_prod_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_str_onehot = [\n",
    "#     'production_companies', \n",
    "#     'production_countries', \n",
    "#     'spoken_languages'\n",
    "# ]\n",
    "# print(train_x['spoken_languages'][0])\n",
    "# print(train_vals_prod_company.shape)\n",
    "# print(train_vals_lang[5])\n",
    "# print(train_vals_prod_country[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offset = np.ones((train_vals_homepage.shape[0], 1))\n",
    "test_offset = np.ones((test_vals_homepage.shape[0], 1))\n",
    "train_vals = np.concatenate((train_vals_homepage, train_vals_tagline, train_vals_onehot, train_vals_real, train_vals_prod_company, train_vals_prod_country, train_vals_lang, train_vals_genres, train_offset), axis=1)\n",
    "test_vals = np.concatenate((test_vals_homepage, test_vals_tagline, test_vals_onehot, test_vals_real, test_vals_prod_company, test_vals_prod_country, test_vals_lang, test_vals_genres, test_offset), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function just computes the mean squared error\n",
    "def MSE(y, pred):\n",
    "    return np.mean(np.square(y - pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function runs OLS and bypasses any SVD (Singular Value Decomposition) convergence errors by refitting the model\n",
    "def run_OLS(train_y, test_y, train_vals, test_vals):\n",
    "    ols_model = sm.regression.linear_model.OLS(train_y, train_vals)\n",
    "    while True: # Bypasses SVD convergence assertion error\n",
    "        try:\n",
    "            results = ols_model.fit()\n",
    "            break\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    w = np.array(results.params).reshape([len(results.params),1])\n",
    "\n",
    "    train_pred = np.matmul(train_vals,w)\n",
    "    test_pred = np.matmul(test_vals,w)\n",
    "\n",
    "    train_MSE = MSE(train_y, train_pred.flatten())\n",
    "    test_MSE = MSE(test_y, test_pred.flatten())\n",
    "    \n",
    "    return train_MSE, test_MSE, test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE\t 4509663465194364.0\n",
      "Test MSE\t 7583628260195321.0\n"
     ]
    }
   ],
   "source": [
    "train_MSE, test_MSE, test_pred = run_OLS(train_y, test_y, train_vals, test_vals)\n",
    "\n",
    "print(\"Train MSE\\t\", str(train_MSE))\n",
    "print(\"Test MSE\\t\", str(test_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(20, 20))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(20, 20))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20, 20))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a nonlinear model\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20))\n",
    "\n",
    "# Train the model on the train set\n",
    "model.fit(train_vals, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.316488668924199\n",
      "Test accuracy: 0.296875\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels of the test set\n",
    "train_pred = model.predict(train_vals)\n",
    "test_pred = model.predict(test_vals)\n",
    "\n",
    "# Evaluate the performance of the model on the test set\n",
    "accuracy_train = accuracy_score(train_y, train_pred)\n",
    "accuracy_test = accuracy_score(test_y, test_pred)\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Train accuracy:\", accuracy_train)\n",
    "print(\"Test accuracy:\", accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv5741': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "557b5432e63c25bc0a47064c92a1c7acaa548717fa75dcf313c4d9862074aa00"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
